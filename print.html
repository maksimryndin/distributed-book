<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Distributed systems for busy engineer</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="preface.html">Preface</a></li><li class="chapter-item expanded "><a href="introduction/overview.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="introduction/network.html"><strong aria-hidden="true">1.1.</strong> Unreliable network</a></li><li class="chapter-item expanded "><a href="introduction/practice.html"><strong aria-hidden="true">1.2.</strong> Measuring network</a></li><li class="chapter-item expanded "><a href="introduction/availability.html"><strong aria-hidden="true">1.3.</strong> Availability</a></li><li class="chapter-item expanded "><a href="introduction/decentralized.html"><strong aria-hidden="true">1.4.</strong> Distributed vs Decentralized</a></li><li class="chapter-item expanded "><a href="introduction/taste-distributed.html"><strong aria-hidden="true">1.5.</strong> Taste of distributed</a></li><li class="chapter-item expanded "><a href="introduction/exercises.html"><strong aria-hidden="true">1.6.</strong> Exercises</a></li></ol></li><li class="chapter-item expanded "><a href="established-systems/overview.html"><strong aria-hidden="true">2.</strong> Established systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="established-systems/erlang.html"><strong aria-hidden="true">2.1.</strong> Erlang/OTP</a></li></ol></li><li class="chapter-item expanded "><a href="consistency/overview.html"><strong aria-hidden="true">3.</strong> Consistency</a></li><li class="chapter-item expanded "><a href="computing/overview.html"><strong aria-hidden="true">4.</strong> Distributed computing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="computing/ml_training.html"><strong aria-hidden="true">4.1.</strong> ML training</a></li></ol></li><li class="chapter-item expanded "><a href="decentralized/overview.html"><strong aria-hidden="true">5.</strong> Decentralized</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="decentralized/p2p.html"><strong aria-hidden="true">5.1.</strong> p2p networks</a></li><li class="chapter-item expanded "><a href="decentralized/blockchain.html"><strong aria-hidden="true">5.2.</strong> Blockchain</a></li><li class="chapter-item expanded "><a href="decentralized/smart_contracts.html"><strong aria-hidden="true">5.3.</strong> Smart contracts</a></li></ol></li><li class="chapter-item expanded "><a href="references.html"><strong aria-hidden="true">6.</strong> References</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Distributed systems for busy engineer</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/maksimryndin/distributed-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="preface"><a class="header" href="#preface">Preface</a></h1>
<p><em>To my girls: wife, daughter, and mom - for their patience and love</em></p>
<h2 id="who-should-read-this-book"><a class="header" href="#who-should-read-this-book">Who should read this book?</a></h2>
<p>To be honest, I don’t have vast practical experience of building distributed systems except the most popular one among web developers (hint: client-server). But a usual requirement to acquire this practical experience is some non-basic knowledge of the topic. So this is a classical “chicken-egg” problem: to work on a distributed software product you are usually required to have some related projects in your portfolio. So writing this book is a way to close these gaps.</p>
<p>Anyway I assume that readers have developed web projects and already have some experience in vertical and horizontal scaling, containerization, data races, classical algorithms and data structures. I will try at my best to introduce all used vocabulary.</p>
<p>I also do not devote any decent time for single machine patterns, as I believe you have enough working practice with them.</p>
<h2 id="why-yet-another-book-on-distributed-systems"><a class="header" href="#why-yet-another-book-on-distributed-systems">Why yet another book on distributed systems?</a></h2>
<p>I’ve read some excellent books devoted to distributed systems or related topics. Among them:</p>
<ul>
<li>Mikito Takada <a href="http://book.mixu.net/distsys/">Distributed systems: for fun and profit</a></li>
<li>Brendan Burns <a href="https://azure.microsoft.com/mediahandler/files/resourcefiles/designing-distributed-systems/Designing_Distributed_Systems.pdf">Designing Distributed Systems</a></li>
<li>Martin Kleppmann <a href="https://dataintensive.net/">Designing Data-Intensive Applications</a></li>
<li>Donne Martin <a href="https://github.com/donnemartin/system-design-primer">System design primer</a></li>
</ul>
<p>All above mentioned books have their own view on what topics and at what level should be covered. Martin Kleppman’s outstanding book (highly recommended) obviously focuses on data-related topics.</p>
<p>Despite I’ve read the books above, I had no clear mental picture and systematic view of Raft Algorithm, Lamport clocks and other distributed buzzwords. So this book tries to cover important topics (choice is subjective, of course) and to serve as a practical guide for busy engineers striving to grasp core concepts in a timely manner.</p>
<p>True understanding comes with real doing, so practice through exercises is a necessary part of learning. I have chosen Rust as a language to use throughout the book as I believe that Rust incorporates modern best practices and solid theoretical achievements. Experienced developers will dive without further ado. But for those who like more gradual involvement I could recommend the following excellent free resources to start with:</p>
<ul>
<li><a href="https://dhghomon.github.io/easy_rust/">Easy Rust</a></li>
<li><a href="https://doc.rust-lang.org/rust-by-example/">Rust by example</a></li>
</ul>
<h2 id="why-should-we-learn-about-distributed-systems"><a class="header" href="#why-should-we-learn-about-distributed-systems">Why should we learn about distributed systems?</a></h2>
<p>I admit that you already know the answer if you’ve started reading the book. But for the sake of completeness let’s enlist some points:</p>
<ul>
<li>modern scalable products inevitably rely on concepts discussed further. So if you want to get working experience in modern tech companies or even build your own product with highload and fault-tolerance in mind, you should grasp the basics<sup class="footnote-reference"><a href="#note">1</a></sup>;</li>
<li>expecting your software being distributed at some point in the future can radically improve your architecture decisions and even determine your preferred stack of technologies to use;</li>
<li>emerging <a href="https://en.wikipedia.org/wiki/Web3">Web 3.0</a> is build around an idea of <em>decentralization</em> which is tightly connected with <em>distributed</em>. So at least you will be able to understand underlying technologies and explore them deeper.</li>
</ul>
<p>The following goal for the book comes out of the points above - <em>get reader familiar with selected topics on distributed systems with strong emphasis on practice</em>.</p>
<h2 id="errata-typos-bugs-and-other-feedback"><a class="header" href="#errata-typos-bugs-and-other-feedback">Errata, typos, bugs and other feedback</a></h2>
<p>I am not a native English speaker so I will be glad to get any feedback on a correct usage of English grammar and phrases. 
Also any suggestions, improvements, fixes are welcome. You can provide merge requests at book’s Github repository or email me at <em>{auhtor’s name}.{author’s last name}@gmail.com</em>.</p>
<h2 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h2>
<p>I would like to tell many kind words to people who influenced me as a software engineer during my career. First of all, the friend of mine, <a href="https://github.com/Farit">Farit Sadykov</a>, who helped me a lot to become a developer. Also my colleagues, especially <a href="https://github.com/softzilla">Pavel Antonov</a>, <a href="https://github.com/dbz-legacy">Nikolay Yurov</a>, <a href="https://github.com/lan-pnz">Vladimir Galkin</a>, Pavel Gorbunov, <a href="https://github.com/andybelov">Andrey Belov</a>, Evgeny Orlov, <a href="https://otus.ru/teacher/1300/">Ilya Zhigalko</a>, Slava Cheremushkin, <a href="https://github.com/kazhuravlev">Kirill Zhuravlev</a>, <a href="https://github.com/scherbakoviv">Ilya Scherbakov</a>.</p>
<p>Also many thanks to open source enthusiasts creating wonderful products, books, and articles, generously sharing knowledge with the rest of the world. We truly stand on the shoulders of giants.</p>
<p><em>Maksim Ryndin</em></p>
<p><em>Montenegro, 2022.</em></p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>Being scalable doesn’t only mean software and infrastructure while adding more servers. It’s also about your team being ready to grow with growing traffic. So being prepared to go distributed is a must-have for every team member in terms of some introductory learning experience, automated pipelines and merge reviews etc.
Please watch very informative <a href="https://www.youtube.com/watch?v=hnpzNAPiC0E">presentation</a> by Lisa Guo on scaling Instagram.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<blockquote>
<p><em>The big idea is “messaging” &lt;..&gt; The key in making great and growable systems is much more to design how its modules communicate rather than what their internal properties and behaviors should be.</em> Alan Kay, creator of Smalltalk<sup class="footnote-reference"><a href="#note">1</a></sup></p>
</blockquote>
<h3 id="what-is-distributed"><a class="header" href="#what-is-distributed">What is distributed?</a></h3>
<blockquote>
<p><em>Distributed system is any system in which a number of independent interconnected computers can cooperate in order to achieve a common goal.</em>
<a href="https://www.oxfordreference.com/search?q=distributed&amp;searchBtn=Search&amp;isQuickSearch=true">Oxford Dictionary of Computer Science</a></p>
</blockquote>
<p>If we have two virtual machines (VM) with a web server on the first VM and a database server on the second one, do we consider such a system distributed? If VMs are on the same physical node, is it a distributed system?
If the web server and the database are running in separate containers and these containers are on different physical nodes, then this system is distributed. But a container orchestrator then moves both containers on the same node. Does the system of two connected containers lose its distributed flavor?</p>
<p>So there are many questions like above and <em>for the purpose of the book</em> we will follow the next definition of a distributed system.</p>
<p><strong>Distributed system is a software which has at least two components interacting with each other only by a network.</strong></p>
<p>If not otherwise specified, we will call components <em>nodes</em> and a group of connected nodes is named <em>cluster</em>.</p>
<p>Even if a network used for communication of the components for the present moment is a loopback interface (“localhost”), it can become a real network for the next deployment.</p>
<h3 id="why-we-need-make-our-software-distributed"><a class="header" href="#why-we-need-make-our-software-distributed">Why we need make our software distributed?</a></h3>
<p>At least, to make it highly <a href="introduction/./availability.html">available</a> at the cost of an increased complexity and managing effort.</p>
<h3 id="overview-of-the-book"><a class="header" href="#overview-of-the-book">Overview of the book</a></h3>
<p>TODO</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p><a href="http://wiki.c2.com/?AlanKayOnMessaging">Re: prototypes vs classes was: Re: Sun’s HotSpot</a></p>
</div>
<div class="footnote-definition" id="graph"><sup class="footnote-definition-label">2</sup>
<p>In this case we have a complete graph, so every node has connections with other <code>n-1</code> nodes. That’s we have <code>n*(n-1)</code> edges but as we count every edge twice, total number of edges is <code>n*(n-1)/2</code>.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unreliable-network"><a class="header" href="#unreliable-network">Unreliable network</a></h1>
<p>Our <a href="introduction/./introduction/overview.html">definition</a> of a distributed system mentions a network as a medium for communication. This medium is a very interesting and complex subject per se but here we only review some core concepts relevant to our study.</p>
<p>A network of interconnected computers is based on some physical layer (Ethernet cables or radio in case of wireless networks)<sup class="footnote-reference"><a href="#osi">1</a></sup>. The physical layer itself is subject to different disruptions, noisiness, and other problems. So we always have to assume that <strong>the network is unreliable</strong> and implement different <em>retry, ordering, and healthcheck policies</em> in our services.</p>
<p>Moreover, network capacity is limited and we should estimate ahead what an amount of data the system under development is going to send through the network.</p>
<blockquote>
<p><strong>Network throughput</strong> is an <em>amount of data that can be transferred through a network within a certain time period</em>
<a href="https://www.oxfordreference.com/search?q=network+throughput&amp;searchBtn=Search&amp;isQuickSearch=true">Oxford Dictionary of the Internet (4 ed.)</a>.</p>
</blockquote>
<p>We can measure a network throughput in bits per second (bit/s or bps) or even in data packets per a unit of time.</p>
<blockquote>
<p><em>Stop&amp;Think</em>: How do you measure a network throughput? How do you estimate a maximum throughput (also called <em>bandwidth</em> or <em>channel capacity</em>) of a network?<sup class="footnote-reference"><a href="#goodput">2</a></sup></p>
</blockquote>
<p>Congestion control algorithms https://cloud.google.com/blog/products/networking/tcp-bbr-congestion-control-comes-to-gcp-your-internet-just-got-faster
https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/net/ipv4/tcp_bbr.c</p>
<p>https://cacm.acm.org/magazines/2017/2/212428-bbr-congestion-based-congestion-control/fulltext</p>
<p>https://dl.acm.org/doi/10.1145/52324.52356</p>
<p>https://github.com/google/bbr</p>
<p>Typical interservice communication within a corporate network often causes to think that the communication is almost instanteneous. But in case of a world wide internet connection spanning several networks the time to deliver data significantly increases.</p>
<blockquote>
<p><strong>Network latency</strong> is <em>the time taken for a given signal or data packet to propagate through a circuit or network from its source point to its destination</em>
<a href="https://www.oxfordreference.com/search?q=network+latency&amp;searchBtn=Search&amp;isQuickSearch=true">Oxford Dictionary of Electronics and Electrical Engineering (5 ed.)</a></p>
</blockquote>
<p>Network latency usually measured from source to destination and back constituting the so called <em>round trip time (RTT)</em> which is rougly speaking a double latency.<sup class="footnote-reference"><a href="#ping">3</a></sup></p>
<p>Caching, keep-alive connections, geoghraphical proximity to the users are among usual options to decrease latency<sup class="footnote-reference"><a href="#os">4</a></sup>.</p>
<p><strong>Network partition</strong> happens if some nodes of a cluster in a distributed system cannot communicate due to a network failure but are supposed to.</p>
<p>Physically nodes (think, computers) in the network are connected by means of <em>network interface</em> controllers (NIC) - a special hardware allowing a computer to connect to the network via a cable (<a href="https://en.wikipedia.org/wiki/Ethernet">Ethernet</a>) or a radio (WiFi). This physical layer is called a <em>link</em> in TCP/IP stack<sup class="footnote-reference"><a href="#tcpip">5</a></sup>. Nodes at the link layer are identified by Media Access Control Address (MAC)</p>
<p>So we have a network of nodes (also called LAN - local area network). How do we <strong>inter</strong>connect <strong>net</strong>works so that we can send a packet with data (called <strong>datagram</strong>) between two hosts from different networks? Here a <em>routing</em> problem arises. Computers called <em>routers</em><sup class="footnote-reference"><a href="#bridge">6</a></sup> a relays between networks and are relaying datagrams from source to destination. But how do we distinguish a host in one network from a host from another network? We need some <em>addressing</em> at an <em>internet layer</em>. IPv4 addressing assigns each host an IP address of the form xx.xx.xx.xx . But with 2^32 unique IP addresses we cannot mark all hosts so IPv6 was developed. Anyway today we still use IPv4 and IPv4 address exaustion was mitigated by so called Network Address Translation (NAT) and private IPs. NAT - explore practically, p2p networks obstacles, violation of end-to-end principle, STUN, private network ips 10.xx.. and 192.168…., 172…
Internet layer is independent of the network topology and physical way of hosts connection.</p>
<p>After we identified a route between to hosts, we can use a <em>transport</em> protocol to, at least, specify <strong>ports</strong> on hosts to connect specific <em>application</em> processes running on hosts involved. Because internet layer is only responsible for routing and for reliability of communication, transport layers protocols can also offer some reliability mechanisms like congestion control, preserves data ordering, eliminate packet loss, provides packet deduplication. Among </p>
<p>So we have a connection between to hosts and we can exchange </p>
<p>TCP/IP processing can also be done at NIC coupled with some user-space library offloading CPU and OS kernel.
https://github.com/Xilinx-CNS/onload.</p>
<p>Network interface
MTU
NAT
Subnet 
Network mask
Broadcasting</p>
<p>So for a distributed system it is absolutely necessary to handle different network failures (which are quite common):</p>
<ul>
<li>meet bandwith requirements and handle network congestion on scaling;</li>
<li>deal with increased latencies;</li>
<li>have policies for network partitions: if a network partition creates two and more subclusters and such subclusters can behave independently (situation known as a <em>split-brain</em><sup class="footnote-reference"><a href="#rabbitmq">7</a></sup>), how should the system evolve and finally merge conflicting states? </li>
</ul>
<div class="footnote-definition" id="osi"><sup class="footnote-definition-label">1</sup>
<p>Most of us have heard about <a href="https://en.wikipedia.org/wiki/OSI_model">OSI model</a> as a theoretical framework to discuss networking stack.</p>
</div>
<div class="footnote-definition" id="goodput"><sup class="footnote-definition-label">2</sup>
<p>Also note that the maximum throughput is not actually an upper limit for <em>application specific data</em> throughput as there is always an overhead of a latency, protocols, encryption, compression, packet retransmission etc. A <strong>useful</strong> data throughput is sometimes called a <em>goodput</em> (see also <a href="https://en.wikipedia.org/wiki/Goodput">Wikipedia Goodput</a>).</p>
</div>
<div class="footnote-definition" id="ping"><sup class="footnote-definition-label">3</sup>
<p>An actual latency measurement is complicated by the presence of several nodes in the packet way, queuing (several packets from different sources to the same destination are put in a waiting list to send) on the gateway, processing delays. Tools like a famous <em>ping</em> can use special control protocols (such as ICMP) which differ from those protocols that you actually use for data (such as TCP) so measurements are biased.</p>
</div>
<div class="footnote-definition" id="os"><sup class="footnote-definition-label">4</sup>
<p>Analyzing your application stack, CPU/IO profile can also help to choose an appropriate operating system if it is possible - see benchmarks <a href="https://www.phoronix.com/scan.php?page=article&amp;item=bsd-linux-eo2021&amp;num=1">Benchmarks: FreeBSD 13 vs. NetBSD 9.2 vs. OpenBSD 7 vs. DragonFlyBSD 6 vs. Linux</a></p>
</div>
<div class="footnote-definition" id="rabbitmq"><sup class="footnote-definition-label">7</sup>
<p><a href="https://www.rabbitmq.com/partitions.html">Clustering and Network Partitions</a></p>
</div>
<div class="footnote-definition" id="tcpip"><sup class="footnote-definition-label">5</sup>
<p>Note that common reference to TCP/IP stack (also called <strong>Internet protocol suite</strong>) includes not only Internet Protocol and Transmission Control Protocol (TCP) but also other protocols such as a User Datagram Protocol (UDP) and QUIC at a transport layer and Internet Protocol Security (IPSec) at an internet layer. TCP/IP stack as a practical network stack predates the OSI theoretical model for general networks.
Since the adoption of TCP/IP in ARPANET in 1983 several proprietary implementations of the stack for different operating systems emerged. But the TCP/IP popularity increased when the University of California at Berkley had open sourced its implementation for BSD Unix  BSD sockets?? (see <a href="https://en.wikipedia.org/wiki/Internet_protocol_suite">Wikipedia Internet protocol suite</a>).</p>
</div>
<div class="footnote-definition" id="private_ips"><sup class="footnote-definition-label">8</sup>
<p>Private IPs are <a href="https://datatracker.ietf.org/doc/html/rfc1918#section-3">defined</a> to belong to the following subnets: 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16. Number after the slash is the <em>network prefix</em> (<a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">CIDR notation</a>) and denotes number of bits which is common for all hosts in the network. So, for example, 192.168.0.0/16 means that the first 16 bits are the same for all hosts and 192.168 in decimal and the rest 16 bits of total 32 bits define the host (2^16 possible addresses in the network). To be correct, the total number of possible addresses should be decreased by two as all binary zeroes hosts denotes the network itself, while all binary one host is the broadcast address. So when you encounter an ip 192.168.12.134, you already know that this ip is not reachable publicly (from the Internet), it is some internal private host.
For IPv6 private ip address (called <a href="https://datatracker.ietf.org/doc/html/rfc4193"><em>unique local address</em></a> starts with a prefix <code>fd</code> (8 bits), then 40 bits of global id (choosen randomly by the operator of the network), then 16 bits for a subnet and the rest 64 bits define the host. So with IPv6 local privates ips are essentially globally unique if 40 bits of global id indeed are random.
Routing protocol experienced revisions 1-4 until becoming well known IPv4 </p>
</div>
<div class="footnote-definition" id="bridge"><sup class="footnote-definition-label">6</sup>
<p>Do not confuse with <a href="https://en.wikipedia.org/wiki/Network_bridge">network bridges</a>. Routers allow spearate networks to communicate while bridges join networks making them a single network.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-your-own-tool-to-measure-network-throughput"><a class="header" href="#create-your-own-tool-to-measure-network-throughput">Create your own tool to measure network throughput</a></h1>
<p>Here we will create our own Rust version of iperf3 to better understand concepts around network</p>
<p>https://github.com/esnet/iperf</p>
<p>Wireshark to analyze packets</p>
<p>Write our own DPI (nDPI, goodbyeDPI)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="availability"><a class="header" href="#availability">Availability</a></h1>
<p>Availability in the common practice is understood as a metric rather than a property of the system. While in the theory of distributed systems (especially, CAP theorem<sup class="footnote-reference"><a href="#kleppmann">1</a></sup>) it is more about property leading to confusion.</p>
<p>We will follow practical considerations and under availability will understand the following concepts.</p>
<blockquote>
<p><em>A service level indicator (SLI) is a carefully defined quantitative measure of some aspect of the level of service that is being provided. It is a metric, not a target.</em><sup class="footnote-reference"><a href="#gcp">2</a></sup></p>
</blockquote>
<p>For example, it can be a ratio of successfully handled requests.</p>
<blockquote>
<p><em>A service level objective (SLO) specifies a target level for the reliability of your service. The SLO is a target value for an SLI.</em><sup class="footnote-reference"><a href="#gcp">2</a></sup></p>
</blockquote>
<p>Service Level Agreement (SLA) declares your commitment to satisfy SLO.
SLO also determines your <em>error budget</em>, i.e. duration of the <a href="https://uptime.is/">allowed downtime</a> within different time periods</p>
<p>Going distributed is just one of the ways to strengthen availability via adding scalabity and redundancy.</p>
<p>Clever design (including API), code quality assurance, proper algorithms, performance tuning, application monitoring, best DevSecOps practices, business and tech metrics collection significantly improves availability and should be considered first before introducing complexity of a distribution.</p>
<div class="footnote-definition" id="kleppmann"><sup class="footnote-definition-label">1</sup>
<p>Martin Kleppmann <a href="https://arxiv.org/abs/1509.05393">A Critique of the CAP Theorem</a></p>
</div>
<div class="footnote-definition" id="gcp"><sup class="footnote-definition-label">2</sup>
<p>Google Cloud Architecture Framework <a href="https://cloud.google.com/architecture/framework/reliability/principles">Reliability principles</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="distributed-vs-decentralized"><a class="header" href="#distributed-vs-decentralized">Distributed vs Decentralized</a></h1>
<blockquote>
<p>Decentralized network is a dispersed network having several or multiple large hubs &lt;..&gt; and no dominant central hub.
<a href="https://www.oxfordreference.com/search?q=decentralized&amp;searchBtn=Search&amp;isQuickSearch=true">Oxford Dictionary of Media and Communication</a></p>
</blockquote>
<p>Consider <a href="https://github.com/donnemartin/system-design-primer#master-slave-replication">master-slave replication</a> of database. We have some slave databases running only read requests and a master database server executing read and writes queries and replicating all changes to slaves. Clearly this system is distributed due to the replication link. If we had no mechanism of promoting slave to master in case of the master’s failure, then our system is not decentralized.</p>
<p>So decentralization insreases fault-tolerance removing single point of failure. But there is also a catch. Consider two network topologies: Mesh (in case of full decentralization) and Star (with central master).</p>
<p><img src="introduction/images/star_mesh.svg" alt="Mesh vs Star" /></p>
<p>So in the case of <code>n</code> nodes of mesh network topology we have <code>n*(n-1)/2</code> connections<sup class="footnote-reference"><a href="#graph">1</a></sup> while in the case of the star network we have only <code>n-1</code> connections. So heavily meshed distributed systems produce increasing network contention.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="taste-of-distributed"><a class="header" href="#taste-of-distributed">Taste of distributed</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="exercises"><a class="header" href="#exercises">Exercises</a></h1>
<ol>
<li>
<p>Due to growing traffic we decided to shard users data by a starting letter of last name. Can we consider such a sharded database as a distributed system? Explain your answer.</p>
</li>
<li>
<p>Model packet loss in the network</p>
</li>
<li>
<p>Implement <a href="https://en.wikipedia.org/wiki/Exponential_backoff">exponential backoff algorithm</a></p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="established-systems"><a class="header" href="#established-systems">Established systems</a></h1>
<blockquote>
<p><em>Successful software is composed not built.</em>
Roger Johansson, creator of ProtoActor</p>
</blockquote>
<p>Implementing distributed systems right way is <a href="https://ferd.ca/lessons-learned-while-working-on-large-scale-server-software.html">hard</a>. In most cases we can compose our software within well established distributed systems. Of course, the goal of the book is to learn how to implement such systems from scratch. But we should be familiar with other options. Some are listed below in the order of decreasing technology lock-in.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="battle-tested-erlangotp"><a class="header" href="#battle-tested-erlangotp">Battle-tested Erlang/OTP</a></h1>
<blockquote>
<p><em>Any sufficiently complicated concurrent program in another language contains an ad hoc informally-specified bug-ridden slow implementation of half of Erlang.</em>
<a href="https://rvirding.blogspot.com/2008/01/virdings-first-rule-of-programming.html">Robert Virding</a>, one of the creators of Erlang</p>
</blockquote>
<p><a href="https://www.erlang.org">Erlang</a> still remains to be a unique fusion of practical engineering and clever architectural vision. Created in 1980s, it still has such a great potential to evolve in a modern web<sup class="footnote-reference"><a href="#klarna">1</a></sup><sup class="footnote-reference"><a href="#my_experience">2</a></sup>.</p>
<p>We won’t dive in the language per se and pragmatic ideas of “let it fail”, <a href="https://adoptingerlang.org/docs/development/supervision_trees/">supervision trees</a>, and fault tolerance. You can read the very concise and full of practical wisdom <a href="https://erlang.org/download/armstrong_thesis_2003.pdf">thesis</a> (highly recommended) of Joe Armstrong, one of the Erlang creators.</p>
<p>Let’s focus more on Erlang distribution capabilities. Erlang is compiled to run in a virtual machine called BEAM<sup class="footnote-reference"><a href="#lumen">3</a></sup>. <a href="https://elixir-lang.org/">Elixir</a> is also a BEAM-runnable language with interoperability with Erlang.</p>
<p>Erlang lightweight processes, while executing application logic, communicate with each other using signals. Most used signal type is a message<sup class="footnote-reference"><a href="#actor">4</a></sup>. Processes are scheduled for execution by BEAM. You can run millions of processes<sup class="footnote-reference"><a href="#erlang_limits">5</a></sup>. OTP is a collection of reusable components (abstractions for concurrent and distributed patterns such as client-server). So Erlang/OTP is a framework allowing you to quickly create complex concurrent and distributed systems.</p>
<p>BEAM (written in C) can be extended with dynamically loaded compiled modules with Native Implemented Functions (<a href="https://www.erlang.org/doc/tutorial/nif.html">NIFs</a>). So you can write this shared module in a language you prefer (supporting C interoperability, of course)<sup class="footnote-reference"><a href="#rustler">6</a></sup>.<br />
Erlang is primarily well suited for a massive IO-bound load so for CPU-bound tasks you should use, for example, above mentioned NIFs<sup class="footnote-reference"><a href="#erlang_io_bound">7</a></sup>.</p>
<p>Every node (Erlang VM) to form a cluster should share the same cookie file with a secret. It is rather a basic “security” with the aim to differentiate two or more clusters.
Every Erlang VM is started with a predefined name and then it’s enough to register the rest <code>n-1</code> nodes on the first node. All nodes sharing the same cookie will propagate connections to each other creating a fully connected mesh network. This default transitive connection propagation can be configured – a node called <em>hidden node</em> without transitive connections can be used to create clusters with less connections<sup class="footnote-reference"><a href="#erlang_distribution">8</a></sup>.</p>
<p>By default, communication between nodes of a cluster is done over TCP.  Separate daemon process (called EPMD - <a href="https://www.erlang.org/doc/man/epmd.html">Erlang Port Mapper Daemon</a>) starts (if not already running) on every host machine with Erlang VMs. EPMD uses DNS to resolve node names to ip addresses and maps node names to ip+port (tcp socket). EPMD serves as a name resolver for nodes on the host machine.</p>
<p><img src="established-systems/images/erlang.svg" alt="Erlang" /></p>
<p>You can also implement your own procedures for <a href="https://www.erlang.org/doc/apps/erts/alt_disco.html">nodes discovery</a> and discovery under <a href="https://contactchanaka.medium.com/erlang-cluster-peer-discovery-on-kubernetes-aa2ed15663f9">container</a> orchestrator.</p>
<p>Default Erlang distribution with cookies assumes trusted network so you should change default communication mechanism in case of untrusted network<sup class="footnote-reference"><a href="#epmdless">9</a></sup>. Moreover, large number of nodes with fully connected mesh communicating over large and uncontrolled network can be prohibitatively costly. This break point may range from 40 to 140 nodes<sup class="footnote-reference"><a href="#erlang_nodes">10</a></sup> depending on load and amount of global state required to sync over cluster (such as a process namespace or getting <code>now</code> time which requires global lock to provide monotonically increasing time over the cluster). In such cases federated<sup class="footnote-reference"><a href="#federated">11</a></sup> clusters and partitioning of global state in separate groups of nodes inside a cluster is a way to go<sup class="footnote-reference"><a href="#erlang_scale">12</a></sup>.</p>
<p>Erlang is actively modernized and continuosly developed. So it’s a solid foundation for a distributed system.</p>
<p><strong>Erlang lessons to go distributed</strong>:</p>
<ul>
<li>separation of concerns and modularity - you can configure your communication transport, algorithm of node discovery, network topology;</li>
<li>distributed system must be observable (Erlang has excellent tracing and monitoring <a href="https://www.erlang.org/doc/man/observer.html">tools</a> allowing to observe even specific Erlang processes);</li>
<li>communication is asynchronous so no node has to wait any acknowledgement that its message was received by another one;</li>
<li>message passing is location transparent (the code to send message to local Erlang process is the same as for sending to a process on another node in the cluster – at a cost of more RAM and time to <code>memcpy</code> as every message is deeply copied);</li>
<li>maintaining global mutable data (namespace of lightweight processes in case of Erlang) and full connectivity severely limits scalability.</li>
</ul>
<div class="footnote-definition" id="klarna"><sup class="footnote-definition-label">1</sup>
<p>For example, Swedish fintech Klarna uses Erlang as it’s core platform handling 2 million transactions per day - look at their <a href="https://jobs.lever.co/klarna?team=Engineering">job descriptions</a>.</p>
</div>
<div class="footnote-definition" id="my_experience"><sup class="footnote-definition-label">2</sup>
<p>At one of my work places I almost convinced my CTO to write IO-bound service for proxying media streams and unary requests in Erlang. For two weeks I read everything on Erlang and finally presented a workable version which was deployed to production. It had worked under production for about 3 weeks till the CTO had a look at the code. He was rather afraid of completely non-imperative style of code and inability to scale his Erlang team (consisted of only me). So he gently asked me to rewrite the app in Go. For those brave of you <a href="https://adoptingerlang.org/">Adopting Erlang</a>.</p>
</div>
<div class="footnote-definition" id="lumen"><sup class="footnote-definition-label">3</sup>
<p>Alternative execution environments (including not only VMs) emerge periodically but I haven’t heard about any production-ready. BEAM is really <a href="https://blog.stenmans.org/theBeamBook/">complicated</a> to reinvent. See also <a href="https://github.com/lumen/lumen">Lumen</a>.</p>
</div>
<div class="footnote-definition" id="actor"><sup class="footnote-definition-label">4</sup>
<p>A lot of holy wars around considering Erlang as an actor language. See <a href="https://softwareengineering.stackexchange.com/questions/277464/is-erlang-really-an-actor-model-language">Stack Exchange question</a> and <a href="http://erlang.org/pipermail/erlang-questions/2014-June/079794.html">Robert Virding’s email</a>.</p>
</div>
<div class="footnote-definition" id="erlang_limits"><sup class="footnote-definition-label">5</sup>
<p>See also <a href="http://erlang.org/documentation/doc-5.8.4/doc/efficiency_guide/advanced.html">http://erlang.org/documentation/doc-5.8.4/doc/efficiency_guide/advanced.html</a></p>
</div>
<div class="footnote-definition" id="rustler"><sup class="footnote-definition-label">6</sup>
<p>See <a href="https://github.com/rusterlium/rustler">Rustler</a></p>
</div>
<div class="footnote-definition" id="erlang_io_bound"><sup class="footnote-definition-label">7</sup>
<p><a href="https://news.ycombinator.com/item?id=15558051">Why we used Pony to write Wallaroo</a>, <a href="https://stackoverflow.com/questions/32846615/what-is-the-best-way-of-doing-computationally-intensive-tasks-in-erlang-w-o-scal"></a></p>
</div>
<div class="footnote-definition" id="erlang_distribution"><sup class="footnote-definition-label">8</sup>
<p><a href="https://www.erlang.org/doc/reference_manual/distributed.html">Distributed Erlang</a></p>
</div>
<div class="footnote-definition" id="epmdless"><sup class="footnote-definition-label">9</sup>
<p>See also <a href="https://github.com/tsloughter/epmdless">epmdless</a>, <a href="https://www.erlang.org/doc/apps/ssl/ssl_distribution.html">Using TLS for Erlang Distribution</a></p>
</div>
<div class="footnote-definition" id="federated"><sup class="footnote-definition-label">11</sup>
<p>Federation is a technique to scale software by grouping its parts by feature. For example, you can federate database in separate servers: one for sessions, second for users, third for sales etc. Increased throughput comes with cost of joining data and holding transactions on the application side.</p>
</div>
<div class="footnote-definition" id="erlang_nodes"><sup class="footnote-definition-label">10</sup>
<p><a href="https://arxiv.org/pdf/1704.07234.pdf">Scaling Reliably: Improving the Scalability of the Erlang Distributed Actor Platform</a></p>
</div>
<div class="footnote-definition" id="erlang_scale"><sup class="footnote-definition-label">12</sup>
<p>See <a href="https://arxiv.org/pdf/1704.07234.pdf">Scaling Reliably: Improving the Scalability of the Erlang Distributed Actor Platform</a>, <a href="https://www.infoq.com/presentations/erland-scale-10000-nodes/">Scaling Erlang Cluster to 10,000 Nodes</a>, <a href="https://stackoverflow.com/questions/5044574/how-scalable-is-distributed-erlang">Stackoverflow question</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><p>Martin Kleppman Critique CAP</p>
<p>latency-sensitivity framework</p>
<p>availability as a metric</p>
<p>operational and network latency</p>
<p>algorithm sensitivity to latency</p>
<p>Network partitions <em>can be modelled as large packet delays (up to the duration of the partition), provided that the duration of the partition is finite and lost packets are retransmitted an unbounded number of times</em><sup class="footnote-reference"><a href="#kleppmann">1</a></sup>.</p>
<div class="footnote-definition" id="kleppmann"><sup class="footnote-definition-label">1</sup>
<p>Martin Kleppmann <a href="https://arxiv.org/abs/1509.05393">A Critique of the CAP Theorem</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="ml-training"><a class="header" href="#ml-training">ML training</a></h1>
<p>Machine learning involves many matrix operations and is naturally parallelized not only within single node but also over distributed nodes. Out-of-box solutions like <a href="https://www.tensorflow.org/guide/distributed_training">Distributed training with TensorFlow</a> transfer parameters (aka weights) from parameters nodes to worker nodes and back during model training. But large parameters matrices for sparse data heavily consume network bandwith and severely decrease model training speed<sup class="footnote-reference"><a href="#twitter">1</a></sup>.</p>
<p>Sparse data means having many null values. For example, <em>unpacked</em> data batch <code>X</code> looks like</p>
<pre><code class="language-ignore">[[0, 0, .., 0, 9], 
 [5,0, .., 0, 34], 
 ...
 [0, .., 720, 14]]
</code></pre>
<p>where total number of rows is a batch size <code>m</code> and each features row is about 2^20 values (yes, it’s a Twitter’s scale).</p>
<p>So the first layer of the network requires 2^20 rows in its parameters matrix <code>W</code> consisting of <code>float32</code> numbers (4 bytes each) and it’s number of columns depends on the next layer size, typically 50 - 400 in case of Twitter. So this results in first layer matrices of 
<code>50 * 2^20  * (4*2^-20) Mb = 200 Mb</code> to <code>400 * 2^20  * (4*2^-20) Mb = 1600 Mb</code>. When you have a lot of worker nodes exhanging gigabyte of data each with parameters servers, your network bandwith is in danger. While first layer is huge, other layers are considerably smaller.</p>
<p>Twitter approaches this scalability problem with a clever nodes organization<sup class="footnote-reference"><a href="#approach">2</a></sup>.</p>
<p>Assume we have <code>K</code> worker nodes, <code>P</code> parameters nodes, and <code>n</code> features in a dataset row.
Then if we break the weights matrix of the first (sparse) layer in <code>P</code> submatrices by features (by columns):</p>
<p><code>X * W</code> = <code>X</code><sub>1</sub><code> * W</code><sub>1</sub> + .. + <code>X</code><sub>P</sub><code> * W</code><sub>P</sub></p>
<p>then each worker node should only work with block of input <code>X</code><sub>i</sub> and block of weights matrix <code>W</code><sub>i</sub>.
Each parameters server <code>i</code> is responsible for i<sup>th</sup> partition <code>W</code><sub>i</sub> of the sparse first layer.</p>
<p>Each worker node runs two processes with the following pseudocode:</p>
<p>Data unpacking and partitioning:</p>
<pre><code class="language-ignore">const m // batch size
const P // number of partitions of the sparse layer

fn process_input() {
    loop {
        batch = receive_input_batch(m) // batch of size m
        for i in 0..P {
            submatrix = unpack_submatrix_i_of_features(batch, i) // with m rows and n/P columns
            send_this_submatrix_to_parameters_server(submatrix, i) // send to server i
        }
    }
}
</code></pre>
<p>Reconstructing output layer of the first sparse layer and training rest layers:</p>
<pre><code class="language-ignore">const P // number of partitions of the sparse layer

fn train_rest_of_layers() {
    loop {
        output_layer // product XW of size m rows (batch size) and n columns (number of features)
        for i in 0..P {
            output_layer += receive_output_submatrix_from_parameters_server(i) // product of block of X and block of W from parameters server i
        }
        calculate_other_layers_of_network(output_layer)
    }
}
</code></pre>
<p>Because the second and further layers are much smaller than the first “sparse” layer, each worker node has these layers locally.</p>
<p>Each parameters node <code>i</code> runs the following process:</p>
<pre><code class="language-ignore">const node_number = i
const K // number of workers

fn train_first_layer() {
    loop {
        Wi // block i of weights matrix for the first sparse layer
        Xi = receive_submatrix_of_features(i)
        block_i = calculate_block_product(Xi, Wi)
        for j in 0..K {
            send_output_layer_block_to_worker(block_i, j) // send to worker j
        }
    }
}
</code></pre>
<p><img src="computing/images/twitter.svg" alt="Twitter ML cluster" /></p>
<p>Such a cluster organization allows for failure and restart of a worker node without loss of weights of the first layer (failure of a parameters node is more damaging). Each worker node is stateless and no transfer of a huge sparse matrix <code>W</code> occurs over network<sup class="footnote-reference"><a href="#results">3</a></sup>.</p>
<div class="footnote-definition" id="twitter"><sup class="footnote-definition-label">1</sup>
<p><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-1">Distributed training of sparse ML models — Part 1: Network bottlenecks</a></p>
</div>
<div class="footnote-definition" id="approach"><sup class="footnote-definition-label">2</sup>
<p><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-2">Distributed training of sparse ML models — Part 2: Optimized strategies</a></p>
</div>
<div class="footnote-definition" id="results"><sup class="footnote-definition-label">3</sup>
<p><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-3">Distributed training of sparse ML models — Part 3: Observed speedups</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="blockchain"><a class="header" href="#blockchain">Blockchain</a></h1>
<p>Permissioned vs permisionless</p>
<p>TPS (transactions per second)</p>
<p>Blockchain network (also called cluster) is p2p network of nodes (called validators in Solana) exchanging with a copy of a ledger (blockchain). Typically 10 - 50 validators totaling 1000-2000 nodes<sup class="footnote-reference"><a href="#validators">1</a></sup></p>
<ul>
<li>distributed state transition requires consensus</li>
</ul>
<p>Smart contracts are run on VM (Sealevel for Solana, EVM for Ethereum)</p>
<p>Client is a program communicating with a cluster via transactions (composed of several intructions in terms of solana). </p>
<p>Transactions are signed by the client by means of Public Key cryptography.</p>
<p>dApp -decentralized app is a UI (typically writen in some Javascript flavor) client </p>
<p>Node which appends new transaction to the ledger is an elected leader.</p>
<p>Token is a unit of payments for computing resources of the cluster (running smart contract or validating its output). You can invest some tokens (delegate a stake) into validator gain a reward. Validator takes some fee (commission) for their services (in bitcoin by including a transaction with 25 BTC out of nowhere<sup class="footnote-reference"><a href="#buterin">2</a></sup>. Growing validators can offer lower commission. It favors large validators to become even larger because lower fee insentives investors to delegate their stakes at a lower commission<sup class="footnote-reference"><a href="#validators oligopoly">3</a></sup>.</p>
<p>If validator behaves maliciously, you los
e your delegated tokens and also validator loses its delegated power and cannot earn more or even as before.</p>
<p>You can use a wallet which is a client allowing you to operate on your token account (send and receive).
To make stakes usually separate stake accounts are used. Solana: Tokens on the stake account can only be invested in the one validator the whole amount at one time. To invest to several validators simultaneously you should use several stake accounts.</p>
<p>How do you get your initial tokens to start? Crypto exchanges (like Binance) allow you to buy some tokens in exchange for a usual currency like US dollars.</p>
<p>Account is typically identified by public key.</p>
<p>Validators advertised their public key.</p>
<p>Bitcoin core can be used to build dApps</p>
<ul>
<li>with bitcoin scripting</li>
<li>with some metaprotocols requiring to use trusted nodes
Or you should invent your own blockchain</li>
</ul>
<p>Buterin suggested EVM to </p>
<div class="footnote-definition" id="validators"><sup class="footnote-definition-label">1</sup>
<p><a href="https://forums.solana.com/t/validator-information-thread/577/51">https://forums.solana.com/t/validator-information-thread/577/51</a></p>
</div>
<div class="footnote-definition" id="validators oligopoly"><sup class="footnote-definition-label">3</sup>
<p>See, for example, Solana’s validators market shares and commissions <a href="https://solanabeach.io/validators">https://solanabeach.io/validators</a></p>
</div>
<div class="footnote-definition" id="buterin"><sup class="footnote-definition-label">2</sup>
<p>(https://ethereum.org/en/whitepaper/)</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>Here are the list of references to cool articles and books etc I’ve used to prepare this book.</p>
<ul>
<li>Mikito Takada <a href="http://book.mixu.net/distsys/">Distributed systems: for fun and profit</a></li>
<li>Brendan Burns <a href="https://azure.microsoft.com/mediahandler/files/resourcefiles/designing-distributed-systems/Designing_Distributed_Systems.pdf">Designing Distributed Systems</a></li>
<li>Martin Kleppmann <a href="https://dataintensive.net/">Designing Data-Intensive Applications</a></li>
<li><a href="https://en.wikipedia.org/wiki/Web3">Wikipedia Web 3.0</a></li>
<li><a href="https://dhghomon.github.io/easy_rust/">Easy Rust</a></li>
<li><a href="https://doc.rust-lang.org/rust-by-example/">Rust by example</a></li>
<li><a href="https://github.com/donnemartin/system-design-primer">System design primer</a></li>
<li><a href="https://www.youtube.com/watch?v=hnpzNAPiC0E">Lisa Guo on scaling Instagram</a></li>
<li><a href="http://wiki.c2.com/?AlanKayOnMessaging">Re: prototypes vs classes was: Re: Sun’s HotSpot</a></li>
<li>Martin Kleppmann <a href="https://arxiv.org/pdf/1509.05393.pdf">A Critique of the CAP Theorem</a></li>
<li>Martin Logan, Eric Merritt, and Richard Carlsson <a href="https://livebook.manning.com/book/erlang-and-otp-in-action/chapter-8/1">Erlang and OTP in Action</a></li>
<li><a href="https://github.com/tsloughter/epmdless">https://github.com/tsloughter/epmdless</a></li>
<li><a href="https://contactchanaka.medium.com/erlang-cluster-peer-discovery-on-kubernetes-aa2ed15663f9">https://contactchanaka.medium.com/erlang-cluster-peer-discovery-on-kubernetes-aa2ed15663f9</a></li>
<li>Joe Armstrong <a href="https://erlang.org/download/armstrong_thesis_2003.pdf">Making reliable distributed systems in the presence of software errors</a></li>
<li><a href="https://www.erlang.org">https://www.erlang.org</a></li>
<li><a href="https://stackoverflow.com/questions/43173196/what-is-the-maximum-practical-number-of-nodes-in-an-erlang-system">https://stackoverflow.com/questions/43173196/what-is-the-maximum-practical-number-of-nodes-in-an-erlang-system</a></li>
<li><a href="https://stackoverflow.com/questions/5044574/how-scalable-is-distributed-erlang">https://stackoverflow.com/questions/5044574/how-scalable-is-distributed-erlang</a></li>
<li><a href="https://news.ycombinator.com/item?id=15558051">Why we used Pony to write Wallaroo</a></li>
<li><a href="https://adoptingerlang.org/">Adopting Erlang</a></li>
<li><a href="https://blog.stenmans.org/theBeamBook/">BEAM book</a></li>
<li><a href="https://stackoverflow.com/questions/32846615/what-is-the-best-way-of-doing-computationally-intensive-tasks-in-erlang-w-o-scal">https://stackoverflow.com/questions/32846615/what-is-the-best-way-of-doing-computationally-intensive-tasks-in-erlang-w-o-scal</a></li>
<li>Timmo Verlaan <a href="https://www.youtube.com/watch?v=F_YUyd_Qdjs">No(de) discovery without DNS &amp; EPMD - Code BEAM STO</a></li>
<li><a href="https://rvirding.blogspot.com/">Robert on anything</a></li>
<li>Phil Trinder et al <a href="https://arxiv.org/pdf/1704.07234.pdf">Scaling Reliably: Improving the Scalability of the Erlang Distributed Actor Platform</a></li>
<li><a href="https://www.infoq.com/presentations/erland-scale-10000-nodes/">Scaling Erlang Cluster to 10,000 Nodes</a></li>
<li><a href="https://softwareengineering.stackexchange.com/questions/277464/is-erlang-really-an-actor-model-language">https://softwareengineering.stackexchange.com/questions/277464/is-erlang-really-an-actor-model-language</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">Fallacies of distributed computing</a></li>
<li>Fred Hebert <a href="https://ferd.ca/lessons-learned-while-working-on-large-scale-server-software.html">Lessons Learned while Working on Large-Scale Server Software</a></li>
<li><a href="https://www.tensorflow.org/guide/distributed_training">Distributed training with TensorFlow</a></li>
<li><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-1">Distributed training of sparse ML models — Part 1: Network bottlenecks</a></li>
<li><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-2">Distributed training of sparse ML models — Part 2: Optimized strategies</a></li>
<li><a href="https://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-3">Distributed training of sparse ML models — Part 3: Observed speedups</a></li>
<li><a href="https://www.ibm.com/topics/what-is-blockchain">What is blockchain technology?</a></li>
<li>Mario Zupan <a href="https://blog.logrocket.com/how-to-build-a-blockchain-in-rust/">How to build a blockchain in Rust</a></li>
<li>Pascal Akunne <a href="https://blog.logrocket.com/guide-blockchain-consensus-protocols/">A guide to blockchain consensus protocols</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a></li>
<li>Satoshi Nakamoto <a href="https://bitcoin.org/bitcoin.pdf">Bitcoin: A Peer-to-Peer Electronic Cash System</a></li>
<li>Chase Barker <a href="https://solana.com/news/getting-started-with-solana-development">Getting Started with Solana Development</a></li>
<li><a href="https://www.youtube.com/watch?v=4dNuMXBjpr0">Solana Core Concepts (Community Video)</a></li>
<li><a href="https://docs.solana.com">Solana Docs</a></li>
<li><a href="https://chorus.one/networks/solana/">https://chorus.one/networks/solana/</a></li>
<li>Felix Lutsch <a href="https://cvj.ch/en/education/basics/the-basics-of-staking/">The Basics of Staking</a></li>
<li>Satoshi Nakamoto <a href="https://bitcoin.org/bitcoin.pdf">Bitcoin: A Peer-to-Peer Electronic Cash System</a></li>
<li><a href="https://medium.com/chorus-one/the-launch-of-chorus-ventures-3b3bee21333">The Launch of Chorus Ventures</a></li>
<li>Nick Szabo <a href="https://www.fon.hum.uva.nl/rob/Courses/InformationInSpeech/CDROM/Literature/LOTwinterschool2006/szabo.best.vwh.net/idea.html">The Idea of Smart Contracts</a></li>
<li>Eddie Xie, Yuanjun Yang <a href="https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/how-we-built-twitter-s-highly-reliable-ads-pacing-service">How we built Twitter’s highly reliable ads pacing service</a></li>
<li><a href="https://habr.com/ru/company/vasexperts/blog/670964/">Взлетит или нет — две разные точки зрения на Web3</a></li>
<li><a href="https://www.ibm.com/cloud/learn/etcd">etcd</a></li>
<li><a href="https://etcd.io/">Etcd official website</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_throughput">Wikipedia Network throughput</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_congestion">Wikipedia Network congestion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Goodput">Wikipedia Goodput</a></li>
<li><a href="https://en.wikipedia.org/wiki/Measuring_network_throughput">Wikipedia Measuring network throughput</a></li>
<li><a href="https://en.wikipedia.org/wiki/Latency_(engineering)">Wikipedia Latency (engineering)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_bridge">Wikipedia Network bridge</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_delay">Wikipedia Network delay</a></li>
<li>Alex Diaconu <a href="https://ably.com/blog/8-fallacies-of-distributed-computing">Navigating the 8 fallacies of distributed computing</a></li>
<li><a href="https://www.aquasec.com/cloud-native-academy/kubernetes-101/kubernetes-complete-guide/">Kubernetes: Why Use It, How It Works, Options and Alternatives</a></li>
<li><a href="https://www.aquasec.com/cloud-native-academy/kubernetes-101/kubernetes-nodes/">Kubernetes Nodes: Components and Basic Operations</a></li>
<li><a href="https://www.rabbitmq.com/partitions.html">Clustering and Network Partitions</a></li>
<li>Martin Kleppmann <a href="https://arxiv.org/abs/1509.05393">A Critique of the CAP Theorem</a></li>
<li><a href="https://www.phoronix.com/scan.php?page=article&amp;item=bsd-linux-eo2021&amp;num=1">Benchmarks: FreeBSD 13 vs. NetBSD 9.2 vs. OpenBSD 7 vs. DragonFlyBSD 6 vs. Linux</a></li>
<li><a href="https://urbit.org">Urbit</a></li>
<li><a href="https://ethereum.org/en/whitepaper/">Ethereum Whitepaper</a></li>
<li><a href="https://urbit.org/blog/urbit-for-normies">Urbit for Normies</a></li>
<li><a href="https://confidentialcomputing.io/whitepaper-01-latest/">Confidential Computing: Hardware-Based Trusted Execution for Applications and Data</a></li>
<li><a href="https://confidentialcomputing.io/wp-content/uploads/sites/85/2022/01/CCC-A-Technical-Analysis-of-Confidential-Computing-v1.2.pdf">A Technical Analysis of Confidential Computing v1.2</a></li>
<li>Brian “Beej Jorgensen” Hall <a href="https://beej.us/guide/bgnet/html/">Beej’s Guide to Network Programming</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_interface_controller">Wikipedia Network interface controller</a></li>
<li><a href="https://en.wikipedia.org/wiki/Internet_protocol_suite">Wikipedia Internet protocol suite</a></li>
<li><a href="https://en.wikipedia.org/wiki/Routing_protocol">Wikipedia Routing protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/IPsec">Wikipedia IPsec</a></li>
<li><a href="https://en.wikipedia.org/wiki/Network_address_translation">Wikipedia Network address translation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Private_network">Wikipedia Private network</a></li>
<li><a href="https://datatracker.ietf.org/doc/html/rfc1918">RFC 1918 Address Allocation for Private Internets</a></li>
<li><a href="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing">Wikipedia Classless Inter-Domain Routing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Subnetwork">Wikipedia Subnetwork</a></li>
<li><a href="https://en.wikipedia.org/wiki/Unique_local_address">Wikipedia Unique local address</a></li>
<li><a href="https://datatracker.ietf.org/doc/html/rfc4193">RFC 4193 Unique Local IPv6 Unicast Addresses</a></li>
<li><a href="https://en.wikipedia.org/wiki/UDP_hole_punching">Wikipedia UDP hole punching</a></li>
<li><a href="https://en.wikipedia.org/wiki/TCP_hole_punching">Wikipedia TCP hole punching</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ethernet">Wikipedia </a></li>
</ul>
<p>https://blog.twitter.com/engineering/en_us/topics/insights/2021/simple-scalable-graph-neural-networks
https://blog.twitter.com/engineering/en_us/topics/insights/2021/fusing-elasticsearch-with-neural-networks-to-identify-data
https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/processing-billions-of-events-in-real-time-at-twitter-
https://blog.twitter.com/engineering/en_us/topics/insights/2021/graph-neural-networks-through-the-lens-of-differential-geometry-
https://blog.twitter.com/engineering/en_us/topics/insights/2022/graph-machine-learning-with-missing-node-features</p>
<p>https://blog.twitter.com/engineering/en_us/topics/open-source/2020/hunting-a-linux-kernel-bug</p>
<p>https://ethereum.org/en/developers/docs/evm/
https://ethereum.github.io/yellowpaper/paper.pdf
https://ethereum.org/en/developers/docs/
https://docs.soliditylang.org/en/v0.6.0/introduction-to-smart-contracts.html#the-ethereum-virtual-machine</p>
<p>https://habr.com/ru/company/yandex/blog/564510/</p>
<p>https://robertgreiner.com/cap-theorem-revisited/</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
